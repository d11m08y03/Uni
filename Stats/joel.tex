\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{mathtools}
\usepackage{pgfplots}
\usepackage{graphicx}
\setlength{\parindent}{0pt}

\newcommand\Mycomb[2][^n]{\prescript{#1\mkern-0.5mu}{}C_{#2}}

\author{
  Vishanraj Daby \\
  \texttt{2314620}
  \and
  Ihsaan Ramjanee \\
  \texttt{2315007}
  \and
  Zakariyya Kurmally \\
  \texttt{2315839}
}

\title{Statistics Assignment}

\begin{document}

\maketitle

\pagebreak

\tableofcontents

\pagebreak

\section{Negative Binomial Distribution (NBD)}
A Bernoulli trial is an experiment that can result in either a
'success' or a 'failure', but not both. \\

Consider a sequence of Bernoulli trials with probability of success
$ p $ and probability of failure $ q $ such that $ 0 \leq p \leq 1 $
and $ p + q = 1 $. If $ X $ is the number of failures before the
$ r^{th} $ success, X is said to follow a NBD with parameters $ r $
and $ p $, denoted by:

\begin{gather*}
  X \sim \text{NBin}(r, p)
\end{gather*}

Note:
\begin{itemize}
  \item Mean is always greater than variance for a NBD. This is 
    known as overdispersion
  \item A random variable D which follows a NBD can also be defined
    as the number of trials until the $ r^{th} $ success. In such a
    case, $ D = (X + r) $
  \item The terms 'success' and 'failure' in a NBD are arbitrary.
    As such, a NBD can also be described as modeling the number
    of successes before a desired number of failures. In this case,
    the roles of $p$ and $q$ are reversed
\end{itemize}

% Relationship beterrn HD

\subsection{Probability Mass Function Of NBD}

\begin{gather*}
  P(X = n) = {{n + r - 1} \choose {r - 1}} p^r q^n, 
  \text{ for } n \in \mathbb{N}, \text{ where } q = 1-p
\end{gather*}

\subsection{Expected Value and Variance of NBD}
\begin{gather*}
  E(X) = \frac{r(1-p)}{p} \\[5pt]
  Var(X) = \frac{r(1-p)}{p^2}
\end{gather*}

\subsection{Assumptions of NBD}
\begin{itemize}
  \item Experiment must have 2 mutually exclusive outcomes denoted as
    'success' or 'failure'
  \item Probability of success must be constant for each trial
  \item Each trial must be independent
  \item The experiment must have a finite number of success(es)
\end{itemize}

\subsection{Relationship between Binomial Distribution (BD) and NBD}
Consider $ n $ independent Bernoulli trials with the same probability 
of success $ p $. If $ Y $ is the number of successes, it is said
to follow a binomial distribution with parameters $ n $ and $ p $
denoted by:

% TODO NBD mean and variance in R generated not in data set

\begin{gather*}
  Y \sim Bin(n, p)
\end{gather*}

Upon comparison, both the BD and NBD are based upon independent 
Bernoulli trials. However, they differ in what they are counting.
The BD counts the number of succeses in a fixed number of 
trials $ n $ while the NBD counts the number of failures until
a fixed number of successes $ r $.

\subsection{Illustration of NBD}
To illustrate, we will use data from Statistics Mauritius pertaining
to grades of student in Economics A Level during the 2023 seating.
Below is a summary of the data collected, along with mean and 
variance.

\begin{center}
  \begin{tabular}{|c|c|c|}
    \hline
    \textbf{Grade} & \textbf{Point Range} & \textbf{$f_i$} \\ % & \textbf{$x_i$} & \textbf{$ f_i \cdot x_i $} & \textbf{$ (x_i - \mu)^2 $} & \textbf{$ f_i \cdot (x_i - \mu)^2  $}\\
    \hline
    \hline
    A* & 129-180	& 75	\\ % & 154.5 & 11587.5	& 5731.441922	& 429858.1441 \\
    A  & 113-129	& 261	\\ % & 120.5 & 31450.5	& 1739.414392	& 453987.1564 \\
    B  & 95-112	  & 435	\\ % & 103.5 & 45022.5	& 610.4006273	& 265524.2729 \\
    C  & 83-95	  & 419	\\ % & 89	  & 37291	  & 104.1682985	& 43646.51705 \\
    D  & 71-83	  & 513	\\ % & 77	  & 39501	  & 3.2174056	  & 1650.529073 \\
    E  & 60-71	  & 490	\\ % & 65.5  & 32095	  & 176.7227999	& 86594.17197 \\
    F  & 0-60	    & 495	\\ % & 30	  & 14850	  & 2380.826409	& 1178509.072 \\
    \hline
  \end{tabular}
\end{center}

From the above data, mean and variance can be calculated as follows:
\begin{gather*}
  E(X) = \frac{\sum x \cdot f}{\sum f} = \frac{163}{50} = 3.26 \\[5pt]
  Var(X) = \frac{(x_i - \mu)^2}{n - 1} = 5.46 
\end{gather*}

Since $ E(X) < Var(X) $, the NBD can be applied. \\

% TODO
% prop credit
% r = 5
% x is not a prob

% \begin{gather*}
%   \mu = \frac{\sum {f_i \cdot x_i}}{\sum f_i} = 78.79 \\[5pt]
%   \sigma = \frac{1}{\sum f_i} \cdot \sum {f_i \cdot (x_i - \mu)^2} = 915.09
% \end{gather*}

\textbf{Scenario:} Consider an event
where A-Level economics students are gathered. The event organiser
wants a group of 5 students who obtained credit and starts 
approaching attendees about their grades one by one
. Let the random variable
$ X $ represent the number of students approached
who have not got a credit until the organiser
has achieved his goal.

% From this, the
% following NBD can be constructed:

% \begin{gather*}
%   X \sim \text{NBin}(3, 0.0279)
% \end{gather*}

Using the rnbinom function in R outputs the following data:

\begin{center}
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|}
    \hline
    x & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 \\
    \hline
    f & 4 & 10 & 8 & 6 & 8 & 6 & 3 & 4 & 0 & 0 & 0 & 1\\
    \hline
  \end{tabular}
\end{center}


\begin{center}
  \includegraphics[scale=0.6]{cock.jpg}
\end{center}

\subsubsection{Issues with this application}

\section{Hypergeometric Distribution (HD)}
Consider a population of $N$ objects which are divided into 2 types: type A and type B.
There are
$n$ objects of type $A$ and $N$ - $n$ objects of type $B$.
Suppose a random sample of size $r$ is taken
(without replacement) from the entire population of $N$ objects. If $X$ 
is the number of objects of
type $A$ in the sample,then $X$ follows a HD with parameters $n$, 
$N-n$ and r denoted by:

\begin{gather*}
  X \sim \text{HGeom}(n, N-n, r)
\end{gather*}

\subsection{Probability Mass Function of HD}

\begin{gather*}
  p(k) =  \frac{\Mycomb[n]{k} \cdot \Mycomb[(N-n)]{(r-k)}}
  {\Mycomb[N]{r}}, \; \;
  \text{for } max\{ 0, r - (N - n) \} \leq k \leq min\{r, n\}
\end{gather*}

\subsection{Expected Value and Variance of HD}
\begin{gather*}
  E(X) = \frac{nr}{N} \\[5pt]
  Var(X) = \frac{nr}{N} \cdot \frac{N -r}{N} \cdot \frac{N-n}{N-1}
\end{gather*}

\subsection{Assumptions of a HD}
\begin{itemize}
  \item Finite population
  \item Population can be seperated into 2 types
  \item Sampling is done without replacement (dependent trials).
\end{itemize}

\subsection{Illustration of a HD}
Here, we will use data from MES concerning the number of students
who sat for the A-Level exams in 2023 in Rodrigues. The following
table shows amount of students classified by gender:

\begin{center}
  \begin{tabular}{|c|c|c|}
    \hline
    \textbf{Male} & \textbf{Female} & \textbf{Total} \\
    \hline
    \hline
    94 & 150 & 244 \\
    \hline
  \end{tabular}
\end{center}

% Let $ X $ be a random variable denoting the number of boys
% in a sample of 30 students.

After this, the following data was generated using the rhyper
function in R, called with:

\begin{center}
  \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
    \hline
    x & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 17 \\
    \hline
    f & 1 & 1 & 3 & 6 & 5 & 4 & 4 & 3 & 2 & 1 \\
    \hline
  \end{tabular}
\end{center}

\begin{center}
  \includegraphics[scale=0.6]{cooked.jpg}
\end{center}

\section{Goodness of Fit}

\subsection{NBD}

Based on the sampled data, the mean and variance can be calculated:

\begin{gather*}
  \mu = \frac{\sum x \cdot f}{\sum f} = \frac{163}{50} = 3.26 \\[5pt]
  \sigma^2 = \frac{(x_i - \mu)^2}{n - 1} = 5.46 \\[5pt]
  \therefore \text{mean < variance}
\end{gather*}

\begin{center}
  \begin{tabular}{|c|c|c|c|}
    \hline
    $x$ & $O_i$ & $ E_i $ (4 d.p) & $ (O_i - E_i)^2 / E_i $ (4 d.p) \\
    \hline 
    \hline 
    0  & 4  & 5.106   & 0.2394 \\
    1  & 10 & 9.3534  & 0.04476 \\
    2  & 8  & 10.2813 & 0.5062 \\
    3  & 6  & 8.7898  & 0.8855 \\
    4  & 8  & 6.4412  & 0.3772 \\
    5  & 6  & 4.2481  & 0.4124 \\
    6  & 3  & 2.5942  & 0.0635 \\
    7  & 4  & 1.4936  & 0.2060 \\
    8  & 0  & 0.8209  & 0.8209 \\
    9  & 0  & 0.4345  & 0.4345 \\
    10 & 0  & 0.2229  & 0.2290 \\
    11 & 1  & 0.1113  & 0.0689 \\
    \hline
    \hline
       & 50 & 49.8968 & 15.2882  \\
    \hline
  \end{tabular}
\end{center}

\begin{gather*}
  x^2 = \sum \frac{(O_i - E_i)^2}{E_i} = 15.2882 \\[5pt]
  x^2_{ll} (0.05) = 19.675 \\[5pt]
\end{gather*}

Since $ x^2 < x^2_{ll}(0.05) $, assuming a 5\% significane level,
the random variable $ X $ does in fact follow a negative binomial
distribution.

\subsection{HD}
\begin{center}
  \begin{tabular}{|c|c|c|c|}
  \hline
    $ x $ & $ O_i $ & $ E_i $ (4 d.p) & $(O_i - E_i)^2 / E_i$ \\
    \hline
    \hline
    7  & 1 & 0.9165 & 0.0076 \\
    8  & 1 & 1.7910 & 0.3493 \\
    9  & 3 & 2.9187 & 0.0023 \\
    10 & 6 & 4.0077 & 0.9904 \\
    11 & 5 & 4.6722 & 0.0230 \\
    12 & 4 & 4.6515 & 0.0913 \\
    13 & 4 & 3.9711 & 0.0002 \\
    14 & 3 & 2.9148 & 0.0025 \\
    15 & 2 & 1.8423 & 0.0135 \\
    17 & 1 & 0.4704 & 0.5963 \\
    \hline
    \hline
       & 30& 28.1562& 2.0764 \\
    \hline
  \end{tabular}
\end{center}

\begin{gather*}
  x^2 = \sum \frac{(O_i - E_i)^2}{E_i} = 2.0764 \\[5pt]
  x^2_9(0.05) = 16.919
\end{gather*}

Since $ x^2 < x^2_9(0.05) $ the random variable X does 
follow a hypergeometric distribution.

\end{document}
